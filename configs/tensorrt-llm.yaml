id: tensorrt-llm
repeats: 3
base_config:
  region: us-chicago-1
  llm_server_type: tensorrt-llm
  data:
    - prompt_tokens=256,generated_tokens=4096
    - prompt_tokens=4096,generated_tokens=256
    - prompt_tokens=2048,generated_tokens=2048
configs:
  - model: zed-industries/zeta
    gpu: H100
    llm_server_config:
      tokenizer: Qwen/Qwen2.5-Coder-7B-Instruct
      llm_kwargs:
        kv_cache_config:
          free_gpu_memory_fraction: 0.1
        build_config:
          plugin_config:
            multiple_profiles: true
            paged_kv_cache: true
            use_paged_context_fmha: true
            gemm_plugin: auto
          max_input_len: 4096
          max_num_tokens: 65536
          max_batch_size: 32
