id: trtllm-engine
configs:
  - model: meta-llama/Llama-3.1-8B-Instruct
    region: us-chicago-1
    llm_server_type: trtllm
    llm_server_config:
      version: 0.17.0.post1
    gpu: H100
    data: prompt_tokens=512,generated_tokens=128
