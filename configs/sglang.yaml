id: sglang
repeats: 3
base_config:
  region: us-chicago-1
  llm_server_type: sglang
  data:
    - prompt_tokens=256,generated_tokens=4096
    - prompt_tokens=4096,generated_tokens=256
    - prompt_tokens=2048,generated_tokens=2048
configs:
  - model: zed-industries/zeta
    gpu: H100
    llm_server_config:
      tokenizer: Qwen/Qwen2.5-Coder-7B-Instruct
  - model: meta-llama/Llama-3.3-70B-Instruct
    gpu: H100:4
    llm_server_config:
      extra_args: ["--tp", "4", "--context-length", "8192"]
  # - model: cognitivecomputations/DeepSeek-V3-0324-AWQ
  #   gpu: H100:8
  #   llm_server_config:
  #     extra_args:
  #       [
  #         "--tp",
  #         "8",
  #         "--context-length",
  #         "8192",
  #         "--mem-fraction-static",
  #         "0.95",
  #         "--dtype",
  #         "half",
  #         "--trust-remote-code",
  #       ]
