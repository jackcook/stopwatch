title: meta-llama/Llama-3.1-8B Benchmark Results
benchmarks:
  - name: Baseline
    config:
      model: meta-llama/Llama-3.1-8B-Instruct
      data: prompt_tokens=512,generated_tokens=1
  - name: With profiler
    config:
      model: meta-llama/Llama-3.1-8B-Instruct
      data: prompt_tokens=512,generated_tokens=1
      vllm_env_vars:
        VLLM_TORCH_PROFILER_DIR: /tmp
        VLLM_RPC_TIMEOUT: "1800000"
